{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haddu</td>\n",
       "      <td>Time vasthe cheppesthanuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINHA</td>\n",
       "      <td>Ha anthey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Haddu</td>\n",
       "      <td>Tq so much na Sodhi antha opika ga vinnanduku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haddu</td>\n",
       "      <td>Suggestions kosam kuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haddu</td>\n",
       "      <td>Chala rojulu iyyindi ila evaritho iyna matladii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SINHA</td>\n",
       "      <td>ðŸ˜… tnx to my playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Haddu</td>\n",
       "      <td>Evarina listener unte bagunnu anipisthundi e m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Haddu</td>\n",
       "      <td>Nv dorikavv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Haddu</td>\n",
       "      <td>Balii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Haddu</td>\n",
       "      <td>ðŸ¤£</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sender                                            Message\n",
       "0  Haddu                          Time vasthe cheppesthanuu\n",
       "1  SINHA                                          Ha anthey\n",
       "2  Haddu      Tq so much na Sodhi antha opika ga vinnanduku\n",
       "3  Haddu                             Suggestions kosam kuda\n",
       "4  Haddu    Chala rojulu iyyindi ila evaritho iyna matladii\n",
       "5  SINHA                               ðŸ˜… tnx to my playlist\n",
       "6  Haddu  Evarina listener unte bagunnu anipisthundi e m...\n",
       "7  Haddu                                        Nv dorikavv\n",
       "8  Haddu                                              Balii\n",
       "9  Haddu                                                  ðŸ¤£"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_file = \"WhatsApp Chat with Haddu.txt\"\n",
    "\n",
    "chat_messages=[]\n",
    "users=[]\n",
    "with open(chat_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    chat_data = file.readlines()\n",
    "    for line in chat_data:\n",
    "        match = re.match(r\"(\\d{2}/\\d{2}/\\d{2}, \\d{2}:\\d{2}) - (.+?): (.+)\", line)\n",
    "        if match:\n",
    "            sender = match.group(2)\n",
    "            message = match.group(3)\n",
    "            chat_messages.append({'Sender':sender,'Message':message})\n",
    "\n",
    "\n",
    "data=pd.DataFrame(chat_messages)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Message\"]=data[\"Message\"].str.lower()\n",
    "\n",
    "data.to_csv(\"chat_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sowmya</td>\n",
       "      <td>&lt;media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sowmya</td>\n",
       "      <td>ðŸ˜‚ðŸ¤£ðŸ¤£ðŸ¤£ðŸ˜‚ idhe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SINHA</td>\n",
       "      <td>oh ok ardam aihindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sowmya</td>\n",
       "      <td>hmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sowmya</td>\n",
       "      <td>hlo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7548</th>\n",
       "      <td>SINHA</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>SINHA</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7550</th>\n",
       "      <td>SINHA</td>\n",
       "      <td>you deleted this message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7551</th>\n",
       "      <td>SINHA</td>\n",
       "      <td>&lt;media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7552</th>\n",
       "      <td>SINHA</td>\n",
       "      <td>&lt;media omitted&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7553 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sender                   Message\n",
       "0     Sowmya           <media omitted>\n",
       "1     Sowmya                ðŸ˜‚ðŸ¤£ðŸ¤£ðŸ¤£ðŸ˜‚ idhe\n",
       "2      SINHA       oh ok ardam aihindi\n",
       "3     Sowmya                       hmm\n",
       "4     Sowmya                       hlo\n",
       "...      ...                       ...\n",
       "7548   SINHA                        ..\n",
       "7549   SINHA                        hi\n",
       "7550   SINHA  you deleted this message\n",
       "7551   SINHA           <media omitted>\n",
       "7552   SINHA           <media omitted>\n",
       "\n",
       "[7553 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"chat_data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Message']=data['Message'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "tokenizer=Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(data['Message'])\n",
    "X=tokenizer.texts_to_sequences(data['Message'])\n",
    "X=pad_sequences(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert sender labels to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder=LabelEncoder()\n",
    "y=label_encoder.fit_transform(data['Sender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=max_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95/95 [==============================] - 6s 39ms/step - loss: 0.5772 - accuracy: 0.6791 - val_loss: 0.4296 - val_accuracy: 0.7862\n",
      "Epoch 2/10\n",
      "95/95 [==============================] - 3s 36ms/step - loss: 0.3131 - accuracy: 0.8504 - val_loss: 0.3717 - val_accuracy: 0.8226\n",
      "Epoch 3/10\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.2173 - accuracy: 0.8903 - val_loss: 0.3969 - val_accuracy: 0.8167\n",
      "Epoch 4/10\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.1831 - accuracy: 0.9065 - val_loss: 0.3905 - val_accuracy: 0.8253\n",
      "Epoch 5/10\n",
      "95/95 [==============================] - 3s 27ms/step - loss: 0.1669 - accuracy: 0.9146 - val_loss: 0.4163 - val_accuracy: 0.8193\n",
      "Epoch 6/10\n",
      "95/95 [==============================] - 3s 27ms/step - loss: 0.1589 - accuracy: 0.9151 - val_loss: 0.4416 - val_accuracy: 0.8015\n",
      "Epoch 7/10\n",
      "95/95 [==============================] - 3s 28ms/step - loss: 0.1569 - accuracy: 0.9151 - val_loss: 0.4421 - val_accuracy: 0.8226\n",
      "Epoch 8/10\n",
      "95/95 [==============================] - 3s 28ms/step - loss: 0.1501 - accuracy: 0.9158 - val_loss: 0.4677 - val_accuracy: 0.8021\n",
      "Epoch 9/10\n",
      "95/95 [==============================] - 3s 28ms/step - loss: 0.1448 - accuracy: 0.9206 - val_loss: 0.4804 - val_accuracy: 0.8173\n",
      "Epoch 10/10\n",
      "95/95 [==============================] - 3s 28ms/step - loss: 0.1435 - accuracy: 0.9220 - val_loss: 0.5032 - val_accuracy: 0.8094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cdb03b130>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.8094\n",
      "Model Accuracy: 0.8093977570533752\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(X_test,y_test)\n",
    "print(\"Model Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-12-25 23:00:58         2210\n",
      "metadata.json                                  2023-12-25 23:00:58           64\n",
      "variables.h5                                   2023-12-25 23:00:58      7271480\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(model,open('./model1.sav','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 350ms/step\n",
      "Predicted Sender: Sowmya\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# New one-line message to test\n",
    "new_message = \"time vasthe cheppesthanu\"\n",
    "\n",
    "# Preprocess the new message using the same tokenizer\n",
    "new_seq = tokenizer.texts_to_sequences([new_message])\n",
    "new_pad = pad_sequences(new_seq, maxlen=max_length)\n",
    "\n",
    "# Predict the sender of the new message\n",
    "prediction = model.predict(new_pad)\n",
    "pred_label=int(np.round(prediction)[0][0])\n",
    "\n",
    "predicted_sender = label_encoder.inverse_transform([pred_label])[0]\n",
    "\n",
    "print(f\"Predicted Sender: {predicted_sender}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
